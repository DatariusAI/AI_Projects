import streamlit as st
import nltk
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.naive_bayes import MultinomialNB

# Try to download nltk data, but with a fallback
try:
    nltk.download('punkt', quiet=True)
except:
    pass  # Silently continue if download fails

# ---------------------------
# Knowledge Base
# ---------------------------
kb = [
    "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù‡Ùˆ ÙØ±Ø¹ Ù…Ù† Ø¹Ù„ÙˆÙ… Ø§Ù„Ø­Ø§Ø³ÙˆØ¨",
    "ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø© Ù‡Ùˆ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
    "Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© Ù„Ù„ØºØ© ØªØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ù„ØºØ©"
]

# ---------------------------
# Simple RAG (TF-IDF)
# ---------------------------
try:
    vectorizer = TfidfVectorizer()
    kb_vectors = vectorizer.fit_transform(kb)
    
    def simple_rag(query):
        query_vec = vectorizer.transform([query])
        similarity = cosine_similarity(query_vec, kb_vectors)
        best_idx = similarity.argmax()
        return kb[best_idx]
except:
    def simple_rag(query):
        return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„."

# ---------------------------
# Simple Sentiment Analysis (Rule-based)
# ---------------------------
positive_words = ["Ø³Ø¹ÙŠØ¯", "Ù…Ù…ØªØ§Ø²", "Ø¬Ù…ÙŠÙ„", "Ø±Ø§Ø¦Ø¹", "Ù…Ø¨Ø³ÙˆØ·", "Ø¬ÙŠØ¯", "Ù…Ø³Ø±ÙˆØ±"]
negative_words = ["Ø­Ø²ÙŠÙ†", "Ø³ÙŠØ¡", "ÙƒØ¦ÙŠØ¨", "Ù…Ù…Ù„", "ØºØ§Ø¶Ø¨", "Ù…Ø¶Ø·Ø±Ø¨"]

def simple_sentiment(text):
    text = text.lower()
    if any(word in text for word in positive_words):
        return "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ"
    elif any(word in text for word in negative_words):
        return "Ø³Ù„Ø¨ÙŠ"
    else:
        return "Ù…Ø­Ø§ÙŠØ¯"

# ---------------------------
# Dialect Identification
# ---------------------------
try:
    dialect_texts = ["Ø¥Ø²Ø§ÙŠÙƒ Ø¹Ø§Ù…Ù„ Ø¥ÙŠÙ‡ØŸ", "Ø´Ù„ÙˆÙ†Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ", "ÙƒÙŠÙÙƒ Ø´Ùˆ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±ØŸ"]
    dialect_labels = ["Egyptian", "Gulf", "Levantine"]
    dialect_vectorizer = TfidfVectorizer()
    X = dialect_vectorizer.fit_transform(dialect_texts)
    dialect_clf = MultinomialNB()
    dialect_clf.fit(X, dialect_labels)
    
    def detect_dialect(text):
        try:
            return dialect_clf.predict(dialect_vectorizer.transform([text]))[0]
        except:
            return "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©"
except:
    def detect_dialect(text):
        return "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©"

# ---------------------------
# Simple summarization (word count based)
# ---------------------------
def basic_summarizer(text, max_words=20):
    words = text.split()
    if len(words) <= max_words:
        return text
    return " ".join(words[:max_words]) + "..."

# ---------------------------
# Simple translation dictionary
# ---------------------------
translations = {
    "Ù…Ø±Ø­Ø¨Ø§": "Hello",
    "ÙƒÙŠÙ Ø­Ø§Ù„Ùƒ": "How are you",
    "Ø´ÙƒØ±Ø§": "Thank you",
    "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ": "Artificial Intelligence"
}

def simple_translate(text):
    return translations.get(text.strip(), "Translation not available")

# ---------------------------
# Streamlit UI
# ---------------------------
st.title("ğŸ¤– Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ")
st.write("Ø§ÙƒØªØ¨ Ø·Ù„Ø¨Ùƒ Ø£Ùˆ Ø³Ø¤Ø§Ù„Ùƒ:")

user_input = st.text_input("Ø§ÙƒØªØ¨ Ù‡Ù†Ø§:")

if st.button("Ø£Ø±Ø³Ù„"):
    if not user_input.strip():
        st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ")
    elif "ØªØ±Ø¬Ù…" in user_input:
        text = user_input.replace("ØªØ±Ø¬Ù…", "").strip()
        st.success(f"Ø§Ù„ØªØ±Ø¬Ù…Ø©: {simple_translate(text)}")
    elif "Ù…Ù„Ø®Øµ" in user_input:
        text = user_input.replace("Ù…Ù„Ø®Øµ", "").strip()
        st.success(f"Ø§Ù„Ù…Ù„Ø®Øµ: {basic_summarizer(text)}")
    elif "Ø´Ø¹ÙˆØ±" in user_input or "Ù…Ø´Ø§Ø¹Ø±" in user_input:
        st.success(f"ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: {simple_sentiment(user_input)}")
    elif "Ù„Ù‡Ø¬Ø©" in user_input:
        text = user_input.replace("Ù„Ù‡Ø¬Ø©", "").strip()
        st.success(f"Ø§Ù„Ù„Ù‡Ø¬Ø©: {detect_dialect(text)}")
    else:
        st.success(f"Ø¥Ø¬Ø§Ø¨Ø©: {simple_rag(user_input)}")

st.markdown("---")
st.markdown("""
**ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:**
- Ø§ÙƒØªØ¨ 'ØªØ±Ø¬Ù…' Ù…ØªØ¨ÙˆØ¹Ù‹Ø§ Ø¨Ø§Ù„Ù†Øµ Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¥Ù„Ù‰ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
- Ø§ÙƒØªØ¨ 'Ù…Ù„Ø®Øµ' Ù…ØªØ¨ÙˆØ¹Ù‹Ø§ Ø¨Ø§Ù„Ù†Øµ Ù„ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†Øµ
- Ø§ÙƒØªØ¨ 'Ø´Ø¹ÙˆØ±' Ø£Ùˆ 'Ù…Ø´Ø§Ø¹Ø±' Ù…ØªØ¨ÙˆØ¹Ù‹Ø§ Ø¨Ø§Ù„Ù†Øµ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
- Ø§ÙƒØªØ¨ 'Ù„Ù‡Ø¬Ø©' Ù…ØªØ¨ÙˆØ¹Ù‹Ø§ Ø¨Ø§Ù„Ù†Øµ Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
- Ø£Ùˆ Ø§ÙƒØªØ¨ Ø£ÙŠ Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù„Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©
""")
