import streamlit as st
from transformers import MarianMTModel, MarianTokenizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics.pairwise import cosine_similarity
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lex_rank import LexRankSummarizer
import nltk

# Download NLTK resources
nltk.download('punkt', quiet=True)

# ---------------------------
# Knowledge Base + TF-IDF (RAG)
# ---------------------------
kb = [
    "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù‡Ùˆ ÙØ±Ø¹ Ù…Ù† Ø¹Ù„ÙˆÙ… Ø§Ù„Ø­Ø§Ø³ÙˆØ¨",
    "ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø© Ù‡Ùˆ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
    "Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© Ù„Ù„ØºØ© ØªØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ù„ØºØ©"
]
vectorizer = TfidfVectorizer()
kb_vectors = vectorizer.fit_transform(kb)

def simple_rag(query):
    query_vec = vectorizer.transform([query])
    similarity = cosine_similarity(query_vec, kb_vectors)
    best_idx = similarity.argmax()
    return kb[best_idx]

# ---------------------------
# Machine Translation (Arabic -> English)
# ---------------------------
@st.cache_resource
def load_translation_model():
    try:
        mt_model_name = "Helsinki-NLP/opus-mt-ar-en"
        mt_tokenizer = MarianTokenizer.from_pretrained(mt_model_name)
        mt_model = MarianMTModel.from_pretrained(mt_model_name)
        return mt_tokenizer, mt_model
    except Exception as e:
        st.error(f"Error loading translation model: {e}")
        return None, None

mt_tokenizer, mt_model = load_translation_model()

def translate(text):
    if mt_tokenizer is None or mt_model is None:
        return "ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ±Ø¬Ù…Ø©"
    
    try:
        tokens = mt_tokenizer(text, return_tensors="pt", padding=True)
        translated = mt_model.generate(**tokens)
        return mt_tokenizer.decode(translated[0], skip_special_tokens=True)
    except Exception as e:
        return f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ±Ø¬Ù…Ø©: {str(e)}"

# ---------------------------
# Simple Sentiment Analysis (Rule-based)
# ---------------------------
positive_words = ["Ø³Ø¹ÙŠØ¯", "Ù…Ù…ØªØ§Ø²", "Ø¬Ù…ÙŠÙ„", "Ø±Ø§Ø¦Ø¹", "Ù…Ø¨Ø³ÙˆØ·", "Ø¬ÙŠØ¯", "Ù…Ø³Ø±ÙˆØ±"]
negative_words = ["Ø­Ø²ÙŠÙ†", "Ø³ÙŠØ¡", "ÙƒØ¦ÙŠØ¨", "Ù…Ù…Ù„", "ØºØ§Ø¶Ø¨", "Ù…Ø¶Ø·Ø±Ø¨"]

def simple_sentiment(text):
    text = text.lower()
    if any(word in text for word in positive_words):
        return "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ"
    elif any(word in text for word in negative_words):
        return "Ø³Ù„Ø¨ÙŠ"
    else:
        return "Ù…Ø­Ø§ÙŠØ¯"

# ---------------------------
# Dialect Identification
# ---------------------------
dialect_texts = ["Ø¥Ø²Ø§ÙŠÙƒ Ø¹Ø§Ù…Ù„ Ø¥ÙŠÙ‡ØŸ", "Ø´Ù„ÙˆÙ†Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ", "ÙƒÙŠÙÙƒ Ø´Ùˆ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±ØŸ"]
dialect_labels = ["Egyptian", "Gulf", "Levantine"]
dialect_vectorizer = TfidfVectorizer()
X = dialect_vectorizer.fit_transform(dialect_texts)
dialect_clf = MultinomialNB()
dialect_clf.fit(X, dialect_labels)

def detect_dialect(text):
    try:
        return dialect_clf.predict(dialect_vectorizer.transform([text]))[0]
    except:
        return "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©"

# ---------------------------
# Summarization (TextRank via sumy)
# ---------------------------
def simple_summarizer(text, num_sentences=2):
    try:
        parser = PlaintextParser.from_string(text, Tokenizer("arabic"))
        summarizer = LexRankSummarizer()
        summary = summarizer(parser.document, num_sentences)
        return " ".join([str(sentence) for sentence in summary])
    except Exception as e:
        return f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ„Ø®ÙŠØµ: {str(e)}"

# ---------------------------
# Streamlit UI
# ---------------------------
def main():
    st.set_page_config(page_title="Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ", page_icon="ğŸ¤–")
    
    st.title("ğŸ¤– Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ")
    st.write("Ø§ÙƒØªØ¨ Ø·Ù„Ø¨Ùƒ Ø£Ùˆ Ø³Ø¤Ø§Ù„Ùƒ:")
    
    # Initialize chat history
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # Display chat history
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # User input
    user_input = st.chat_input("Ø§ÙƒØªØ¨ Ù‡Ù†Ø§...")
    
    if user_input:
        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        # Display user message in chat
        with st.chat_message("user"):
            st.markdown(user_input)
        
        # Process the input and generate a response
        response = process_input(user_input)
        
        # Add assistant response to chat history
        st.session_state.messages.append({"role": "assistant", "content": response})
        
        # Display assistant response in chat
        with st.chat_message("assistant"):
            st.markdown(response)

def process_input(user_input):
    if user_input.strip() == "":
        return "Ù…Ù† ÙØ¶Ù„Ùƒ Ø£Ø¯Ø®Ù„ Ù†ØµØ§Ù‹."
    
    elif "ØªØ±Ø¬Ù…" in user_input:
        text_to_translate = user_input.replace("ØªØ±Ø¬Ù…", "").strip()
        result = translate(text_to_translate)
        return f"**Ø§Ù„ØªØ±Ø¬Ù…Ø©:**\n{result}"
    
    elif "Ù…Ù„Ø®Øµ" in user_input:
        text_to_summarize = user_input.replace("Ù…Ù„Ø®Øµ", "").strip()
        result = simple_summarizer(text_to_summarize)
        return f"**Ø§Ù„Ù…Ù„Ø®Øµ:**\n{result}"
    
    elif "Ø´Ø¹ÙˆØ±" in user_input or "Ù…Ø´Ø§Ø¹Ø±" in user_input:
        result = simple_sentiment(user_input)
        return f"**ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±:**\n{result}"
    
    elif "Ù„Ù‡Ø¬Ø©" in user_input:
        text_to_analyze = user_input.replace("Ù„Ù‡Ø¬Ø©", "").strip()
        result = detect_dialect(text_to_analyze)
        return f"**Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ÙƒØªØ´ÙØ©:**\n{result}"
    
    else:
        result = simple_rag(user_input)
        return f"**Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©:**\n{result}"

if __name__ == "__main__":
    main()
