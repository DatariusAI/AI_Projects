import streamlit as st
from transformers import pipeline, MarianMTModel, MarianTokenizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics.pairwise import cosine_similarity
from camel_tools.sentiment import SentimentAnalyzer
import nltk

# Download nltk
nltk.download('punkt')

# ---------------------------
# Knowledge Base + TF-IDF
# ---------------------------
kb = ["Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù‡Ùˆ ÙØ±Ø¹ Ù…Ù† Ø¹Ù„ÙˆÙ… Ø§Ù„Ø­Ø§Ø³ÙˆØ¨",
      "ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„Ø© Ù‡Ùˆ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
      "Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© Ù„Ù„ØºØ© ØªØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ù„ØºØ©"]

vectorizer = TfidfVectorizer()
kb_vectors = vectorizer.fit_transform(kb)

def simple_rag(query):
    query_vec = vectorizer.transform([query])
    similarity = cosine_similarity(query_vec, kb_vectors)
    best_idx = similarity.argmax()
    return kb[best_idx]

# ---------------------------
# Machine Translation (Arabic -> English)
# ---------------------------
mt_model_name = "Helsinki-NLP/opus-mt-ar-en"
mt_tokenizer = MarianTokenizer.from_pretrained(mt_model_name)
mt_model = MarianMTModel.from_pretrained(mt_model_name)

def translate(text):
    tokens = mt_tokenizer(text, return_tensors="pt", padding=True)
    translated = mt_model.generate(**tokens)
    return mt_tokenizer.decode(translated[0], skip_special_tokens=True)

# ---------------------------
# Sentiment Analysis (camel-tools)
# ---------------------------
sentiment_analyzer = SentimentAnalyzer.pretrained()

def simple_sentiment(text):
    return sentiment_analyzer.predict(text)

# ---------------------------
# Dialect Identification
# ---------------------------
dialect_texts = ["Ø¥Ø²Ø§ÙŠÙƒ Ø¹Ø§Ù…Ù„ Ø¥ÙŠÙ‡ØŸ", "Ø´Ù„ÙˆÙ†Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ", "ÙƒÙŠÙÙƒ Ø´Ùˆ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±ØŸ"]
dialect_labels = ["Egyptian", "Gulf", "Levantine"]
dialect_vectorizer = TfidfVectorizer()
X = dialect_vectorizer.fit_transform(dialect_texts)
dialect_clf = MultinomialNB()
dialect_clf.fit(X, dialect_labels)

def detect_dialect(text):
    return dialect_clf.predict(dialect_vectorizer.transform([text]))[0]

# ---------------------------
# Summarization
# ---------------------------
summarizer = pipeline("summarization", model="csebuetnlp/mT5_multilingual_XLSum")

# ---------------------------
# Streamlit UI
# ---------------------------
st.set_page_config(page_title="Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ", page_icon="ğŸ¤–")
st.title("ğŸ¤– Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ")

st.write("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø£Ùˆ Ø·Ù„Ø¨Ùƒ ÙÙŠ Ø§Ù„Ù…Ø±Ø¨Ø¹ Ø£Ø¯Ù†Ø§Ù‡:")

user_input = st.text_input("Ø§ÙƒØªØ¨ Ù‡Ù†Ø§:")

if st.button("Ø£Ø±Ø³Ù„"):

    if user_input.strip() == "":
        st.write("Ù…Ù† ÙØ¶Ù„Ùƒ Ø£Ø¯Ø®Ù„ Ù†ØµØ§Ù‹.")
    
    elif "ØªØ±Ø¬Ù…" in user_input:
        result = translate(user_input.replace("ØªØ±Ø¬Ù…", ""))
        st.write("**Ø§Ù„ØªØ±Ø¬Ù…Ø©:**", result)

    elif "Ù…Ù„Ø®Øµ" in user_input:
        result = summarizer(user_input, max_length=40, min_length=10)[0]['summary_text']
        st.write("**Ø§Ù„Ù…Ù„Ø®Øµ:**", result)

    elif "Ø´Ø¹ÙˆØ±" in user_input:
        result = simple_sentiment(user_input)
        st.write("**Ø§Ù„Ù…Ø´Ø§Ø¹Ø±:**", result)

    elif "Ù„Ù‡Ø¬Ø©" in user_input:
        result = detect_dialect(user_input)
        st.write("**Ø§Ù„Ù„Ù‡Ø¬Ø©:**", result)

    else:
        result = simple_rag(user_input)
        st.write("**Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©:**", result)
